{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lda\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_data = pd.read_csv('Data/CF_Fatma_label_confidence_judgments_finalized_clean_text_28_05_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled_tweets = pd.read_csv('Data/unlabeled_turkish_tweets_processd.csv')\n",
    "df_unlabeled_tweets = df_unlabeled_tweets.dropna()\n",
    "df_unlabeled_tweets = df_unlabeled_tweets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_data = df_cf_data[['clean_text', 'Fatma_violence']]\n",
    "df_unlabeled_tweets = df_unlabeled_tweets[['clean_text', 'Fatma_violence']]\n",
    "df_tweets = pd.concat([df_cf_data, df_unlabeled_tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 4 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(df_cf_data.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1214, 4)\n"
     ]
    }
   ],
   "source": [
    "# Build a Latent Semantic Indexing Model\n",
    "lsi_model = TruncatedSVD(n_components=4)\n",
    "lsi_Z = lsi_model.fit_transform(cvz)\n",
    "print(lsi_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI Model:\n",
      "Topic 0:\n",
      "[('police', 0.8718562469979186), ('square', 0.2171728374096674), ('gas', 0.18810026703033117), ('people', 0.15608124809970003), ('tear', 0.15068607490458125), ('erdogan', 0.11556924004007604), ('riot', 0.09498163735892766), ('ankara', 0.08247301914043668), ('violence', 0.07844153044830099), ('attack', 0.0744780137704591)]\n",
      "Topic 1:\n",
      "[('erdogan', 0.8920633089673118), ('says', 0.175582091957604), ('people', 0.16463127373564582), ('minister', 0.12261595810007266), ('prime', 0.10193634253516726), ('media', 0.09693102467495528), ('world', 0.08141696379309585), ('news', 0.06526952441576764), ('opposition', 0.05843772471424674), ('united', 0.050931761430265676)]\n",
      "Topic 2:\n",
      "[('need', 0.5408581648891233), ('understand', 0.5199191929407079), ('things', 0.5196089446418974), ('violence', 0.1081985882773863), ('want', 0.10407347116717146), ('stop', 0.1018786148411038), ('good', 0.0986287209253838), ('burgers', 0.09084919767210617), ('nice', 0.08977010054938288), ('better', 0.08948786870437356)]\n",
      "Topic 3:\n",
      "[('gas', 0.6780700210412179), ('tear', 0.5688282157884048), ('understand', 0.13747766006735498), ('need', 0.13707436777601895), ('things', 0.13672224439572733), ('water', 0.11565315839990141), ('photo', 0.07303755732263163), ('cannon', 0.06062929947474789), ('fired', 0.04518651797986692), ('woman', 0.043269554147604576)]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"LSI Model:\")\n",
    "print_topics(lsi_model, cvectorizer)\n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1214 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1214 samples in 0.048s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1214\n",
      "[t-SNE] Computed conditional probabilities for sample 1214 / 1214\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 54.380810\n"
     ]
    }
   ],
   "source": [
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "# 20-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(lsi_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\"#1f77b4\", \"#FF0000\",'#6AA84F', '#E69138', '#A64D79']) #, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(lsi_Z.shape[0]):\n",
    "  _lda_keys +=  lsi_Z[i].argmax(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summaries = []\n",
    "topic_word = lsi_model.components_# all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "  topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "_idx = np.amax(lsi_Z, axis=1) > threshold  # idx of doc that above the threshold\n",
    "X_topics = lsi_Z[_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['police square gas people tear', 'erdogan says people minister prime']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
