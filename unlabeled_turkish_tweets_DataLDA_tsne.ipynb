{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lda\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = pd.read_csv('Data/unlabeled_turkish_tweets_processd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = df_cf.drop_duplicates()\n",
    "df_cf = df_cf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cf.clean_text[:2000]\n",
    "y = df_cf.Fatma_violence[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 5 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(X)\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = lda.LDA(n_topics=n_topics, n_iter=n_iter)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2000\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 0.305054\n",
      "[t-SNE] Error after 225 iterations: 0.305054\n"
     ]
    }
   ],
   "source": [
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "# 20-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\"#1f77b4\", \"#FF0000\", '#6AA84F', '#E69138', '#A64D79'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in xrange(X_topics.shape[0]):\n",
    "  _lda_keys +=  X_topics[i].argmax(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "  topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = lda_model.topic_word_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "_idx = np.amax(X_topics, axis=1) > threshold  # idx of doc that above the threshold\n",
    "X_topics = X_topics[_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'occupygezi turkey police direngeziparki istanbul',\n",
       " u'turkey erdogan istanbul protests taksim',\n",
       " u'turkey gezi park protests turkish',\n",
       " u'turkey know like going world',\n",
       " u'taksim police istanbul occupygezi turkey']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bokeh.models.renderers.GlyphRenderer at 0x7fdd893935d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'unlabeled turkish LDA viz'\n",
    "num_example = len(X_topics)\n",
    "\n",
    "plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
    "                     title=title,\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
    "                 color=colormap[_lda_keys][:num_example],\n",
    "                 source=bp.ColumnDataSource({\n",
    "                   \"content\": X[:num_example],\n",
    "                   \"topic_key\": _lda_keys[:num_example]\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatma/anaconda2/lib/python2.7/site-packages/bokeh/io.py:371: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warnings.warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "/home/fatma/anaconda2/lib/python2.7/site-packages/bokeh/io.py:376: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warnings.warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    }
   ],
   "source": [
    "# randomly choose a news (within a topic) coordinate as the crucial words coordinate\n",
    "topic_coord = np.empty((X_topics.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "  if not np.isnan(topic_coord).any():\n",
    "    break\n",
    "  topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]\n",
    "\n",
    "# plot crucial words\n",
    "for i in xrange(X_topics.shape[1]):\n",
    "  plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])\n",
    "\n",
    "# hover tools\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "# save the plot\n",
    "save(plot_lda, '{}.html'.format(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
